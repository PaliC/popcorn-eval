==PROF== Connected to process 2043076 (/home/sahanp/.conda/envs/parity-bench/bin/python3.11)
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Profiling "matmul_kernel": 0%....50%....100% - 8 passes
==PROF== Disconnected from process 2043076
[2043076] python3.11@127.0.0.1
  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,839
    Memory Throughput                   %         3.75
    DRAM Throughput                     %         2.96
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        52.80
    L2 Cache Throughput                 %         6.45
    SM Active Cycles                cycle       887.58
    Compute (SM) Throughput             %         2.53
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.43
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,825
    Memory Throughput                   %         3.72
    DRAM Throughput                     %         2.97
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        52.21
    L2 Cache Throughput                 %         6.27
    SM Active Cycles                cycle       898.74
    Compute (SM) Throughput             %         2.53
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.43
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,609
    Memory Throughput                   %         3.75
    DRAM Throughput                     %         3.00
    Duration                      usecond        14.56
    L1/TEX Cache Throughput             %        52.86
    L2 Cache Throughput                 %         6.70
    SM Active Cycles                cycle       887.42
    Compute (SM) Throughput             %         2.56
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.43
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,809
    Memory Throughput                   %         3.75
    DRAM Throughput                     %         2.97
    Duration                      usecond        14.72
    L1/TEX Cache Throughput             %        52.17
    L2 Cache Throughput                 %         6.37
    SM Active Cycles                cycle       897.94
    Compute (SM) Throughput             %         2.53
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.43
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,479
    Memory Throughput                   %         3.05
    DRAM Throughput                     %         3.05
    Duration                      usecond        14.46
    L1/TEX Cache Throughput             %        51.97
    L2 Cache Throughput                 %         2.82
    SM Active Cycles                cycle       900.94
    Compute (SM) Throughput             %         2.57
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.43
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.34
    Elapsed Cycles                  cycle       19,815
    Memory Throughput                   %         3.71
    DRAM Throughput                     %         2.97
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        52.14
    L2 Cache Throughput                 %         6.21
    SM Active Cycles                cycle       898.34
    Compute (SM) Throughput             %         2.53
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.44
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,779
    Memory Throughput                   %         3.70
    DRAM Throughput                     %         2.98
    Duration                      usecond        14.69
    L1/TEX Cache Throughput             %        52.65
    L2 Cache Throughput                 %         6.52
    SM Active Cycles                cycle       889.39
    Compute (SM) Throughput             %         2.53
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.43
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (8, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.33
    Elapsed Cycles                  cycle       19,703
    Memory Throughput                   %         3.75
    DRAM Throughput                     %         2.99
    Duration                      usecond        14.66
    L1/TEX Cache Throughput             %        52.13
    L2 Cache Throughput                 %         6.20
    SM Active Cycles                cycle       901.57
    Compute (SM) Throughput             %         2.54
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     256
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                        8
    Registers Per Thread             register/thread               214
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block            147.46
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 132             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block            1
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %        12.44
    Achieved Active Warps Per SM           warp         7.96
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       13,555
    Memory Throughput                   %         7.37
    DRAM Throughput                     %         4.04
    Duration                      usecond        10.88
    L1/TEX Cache Throughput             %        43.52
    L2 Cache Throughput                 %        10.07
    SM Active Cycles                cycle     1,190.68
    Compute (SM) Throughput             %         3.67
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       13,155
    Memory Throughput                   %         7.57
    DRAM Throughput                     %         4.14
    Duration                      usecond        10.56
    L1/TEX Cache Throughput             %        44.89
    L2 Cache Throughput                 %        10.36
    SM Active Cycles                cycle     1,155.18
    Compute (SM) Throughput             %         3.78
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       12,991
    Memory Throughput                   %         7.68
    DRAM Throughput                     %         4.18
    Duration                      usecond        10.43
    L1/TEX Cache Throughput             %        44.44
    L2 Cache Throughput                 %        10.57
    SM Active Cycles                cycle     1,168.36
    Compute (SM) Throughput             %         3.83
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       13,169
    Memory Throughput                   %         7.60
    DRAM Throughput                     %         4.14
    Duration                      usecond        10.59
    L1/TEX Cache Throughput             %        44.06
    L2 Cache Throughput                 %        10.63
    SM Active Cycles                cycle     1,179.95
    Compute (SM) Throughput             %         3.78
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.25
    Elapsed Cycles                  cycle       13,974
    Memory Throughput                   %         7.17
    DRAM Throughput                     %         3.92
    Duration                      usecond        11.17
    L1/TEX Cache Throughput             %        44.55
    L2 Cache Throughput                 %         9.92
    SM Active Cycles                cycle     1,160.69
    Compute (SM) Throughput             %         3.56
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       13,339
    Memory Throughput                   %         7.48
    DRAM Throughput                     %         4.10
    Duration                      usecond        10.69
    L1/TEX Cache Throughput             %        44.31
    L2 Cache Throughput                 %        10.34
    SM Active Cycles                cycle     1,163.74
    Compute (SM) Throughput             %         3.73
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       13,333
    Memory Throughput                   %         7.50
    DRAM Throughput                     %         4.08
    Duration                      usecond        10.69
    L1/TEX Cache Throughput             %        43.21
    L2 Cache Throughput                 %        10.36
    SM Active Cycles                cycle     1,199.74
    Compute (SM) Throughput             %         3.73
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       13,128
    Memory Throughput                   %         7.58
    DRAM Throughput                     %         4.15
    Duration                      usecond        10.56
    L1/TEX Cache Throughput             %        44.27
    L2 Cache Throughput                 %        10.40
    SM Active Cycles                cycle     1,172.55
    Compute (SM) Throughput             %         3.79
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               200
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA Best           
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,034
    Memory Throughput                   %         6.95
    DRAM Throughput                     %         3.88
    Duration                      usecond        11.26
    L1/TEX Cache Throughput             %        43.13
    L2 Cache Throughput                 %        10.13
    SM Active Cycles                cycle     1,282.76
    Compute (SM) Throughput             %         3.55
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,121
    Memory Throughput                   %         6.91
    DRAM Throughput                     %         3.86
    Duration                      usecond        11.36
    L1/TEX Cache Throughput             %        43.07
    L2 Cache Throughput                 %        10.25
    SM Active Cycles                cycle     1,286.05
    Compute (SM) Throughput             %         3.52
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,174
    Memory Throughput                   %         6.88
    DRAM Throughput                     %         3.84
    Duration                      usecond        11.39
    L1/TEX Cache Throughput             %        43.30
    L2 Cache Throughput                 %        10.03
    SM Active Cycles                cycle     1,276.94
    Compute (SM) Throughput             %         3.51
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,133
    Memory Throughput                   %         6.91
    DRAM Throughput                     %         3.86
    Duration                      usecond        11.33
    L1/TEX Cache Throughput             %        43.15
    L2 Cache Throughput                 %        10.21
    SM Active Cycles                cycle     1,284.30
    Compute (SM) Throughput             %         3.52
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,044
    Memory Throughput                   %         6.98
    DRAM Throughput                     %         3.87
    Duration                      usecond        11.30
    L1/TEX Cache Throughput             %        43.29
    L2 Cache Throughput                 %        10.16
    SM Active Cycles                cycle     1,280.19
    Compute (SM) Throughput             %         3.54
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,081
    Memory Throughput                   %         6.95
    DRAM Throughput                     %         3.86
    Duration                      usecond        11.33
    L1/TEX Cache Throughput             %        43.19
    L2 Cache Throughput                 %        10.32
    SM Active Cycles                cycle     1,283.77
    Compute (SM) Throughput             %         3.53
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,029
    Memory Throughput                   %         6.97
    DRAM Throughput                     %         3.87
    Duration                      usecond        11.30
    L1/TEX Cache Throughput             %        43.01
    L2 Cache Throughput                 %        10.35
    SM Active Cycles                cycle     1,287.16
    Compute (SM) Throughput             %         3.55
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,215
    Memory Throughput                   %         6.90
    DRAM Throughput                     %         3.83
    Duration                      usecond        11.39
    L1/TEX Cache Throughput             %        42.62
    L2 Cache Throughput                 %        10.14
    SM Active Cycles                cycle     1,302.86
    Compute (SM) Throughput             %         3.50
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,845
    Memory Throughput                   %        10.65
    DRAM Throughput                     %         4.56
    Duration                      usecond         9.57
    L1/TEX Cache Throughput             %        37.09
    L2 Cache Throughput                 %        12.14
    SM Active Cycles                cycle     1,983.12
    Compute (SM) Throughput             %         4.28
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,656
    Memory Throughput                   %        10.57
    DRAM Throughput                     %         4.61
    Duration                      usecond         9.44
    L1/TEX Cache Throughput             %        37.28
    L2 Cache Throughput                 %        12.16
    SM Active Cycles                cycle     1,971.20
    Compute (SM) Throughput             %         4.35
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,976
    Memory Throughput                   %        10.69
    DRAM Throughput                     %         4.50
    Duration                      usecond         9.70
    L1/TEX Cache Throughput             %        36.21
    L2 Cache Throughput                 %        11.88
    SM Active Cycles                cycle     2,026.24
    Compute (SM) Throughput             %         4.23
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,782
    Memory Throughput                   %        10.58
    DRAM Throughput                     %         4.57
    Duration                      usecond         9.50
    L1/TEX Cache Throughput             %        36.66
    L2 Cache Throughput                 %        12.20
    SM Active Cycles                cycle     2,037.95
    Compute (SM) Throughput             %         4.31
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,728
    Memory Throughput                   %        10.48
    DRAM Throughput                     %         4.60
    Duration                      usecond         9.50
    L1/TEX Cache Throughput             %        37.21
    L2 Cache Throughput                 %        12.26
    SM Active Cycles                cycle     2,000.03
    Compute (SM) Throughput             %         4.33
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,958
    Memory Throughput                   %        10.39
    DRAM Throughput                     %         4.52
    Duration                      usecond         9.66
    L1/TEX Cache Throughput             %        37.12
    L2 Cache Throughput                 %        12.24
    SM Active Cycles                cycle     1,985.72
    Compute (SM) Throughput             %         4.24
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,831
    Memory Throughput                   %        10.51
    DRAM Throughput                     %         4.57
    Duration                      usecond         9.57
    L1/TEX Cache Throughput             %        36.89
    L2 Cache Throughput                 %        12.06
    SM Active Cycles                cycle     2,015.62
    Compute (SM) Throughput             %         4.29
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,882
    Memory Throughput                   %        10.36
    DRAM Throughput                     %         4.54
    Duration                      usecond         9.60
    L1/TEX Cache Throughput             %        37.11
    L2 Cache Throughput                 %        12.16
    SM Active Cycles                cycle     2,006.55
    Compute (SM) Throughput             %         4.27
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             116
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,500
    Memory Throughput                   %         9.46
    DRAM Throughput                     %         5.37
    Duration                      usecond         9.31
    L1/TEX Cache Throughput             %        31.66
    L2 Cache Throughput                 %        13.71
    SM Active Cycles                cycle        1,997
    Compute (SM) Throughput             %         4.37
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,344
    Memory Throughput                   %         9.61
    DRAM Throughput                     %         4.79
    Duration                      usecond         9.18
    L1/TEX Cache Throughput             %        32.66
    L2 Cache Throughput                 %         9.61
    SM Active Cycles                cycle     1,926.86
    Compute (SM) Throughput             %         4.44
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,473
    Memory Throughput                   %         9.97
    DRAM Throughput                     %         5.17
    Duration                      usecond         9.28
    L1/TEX Cache Throughput             %        31.45
    L2 Cache Throughput                 %        13.50
    SM Active Cycles                cycle     2,012.33
    Compute (SM) Throughput             %         4.38
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,578
    Memory Throughput                   %         9.39
    DRAM Throughput                     %         4.65
    Duration                      usecond         9.38
    L1/TEX Cache Throughput             %        32.77
    L2 Cache Throughput                 %        13.59
    SM Active Cycles                cycle     1,940.07
    Compute (SM) Throughput             %         4.34
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,531
    Memory Throughput                   %         9.31
    DRAM Throughput                     %         4.68
    Duration                      usecond         9.28
    L1/TEX Cache Throughput             %        33.00
    L2 Cache Throughput                 %        13.35
    SM Active Cycles                cycle     1,909.67
    Compute (SM) Throughput             %         4.36
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.60
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,511
    Memory Throughput                   %         9.41
    DRAM Throughput                     %         4.66
    Duration                      usecond         9.28
    L1/TEX Cache Throughput             %        32.09
    L2 Cache Throughput                 %        13.47
    SM Active Cycles                cycle     1,961.30
    Compute (SM) Throughput             %         4.37
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,390
    Memory Throughput                   %         9.44
    DRAM Throughput                     %         4.73
    Duration                      usecond         9.22
    L1/TEX Cache Throughput             %        32.10
    L2 Cache Throughput                 %        13.84
    SM Active Cycles                cycle     1,970.57
    Compute (SM) Throughput             %         4.42
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,527
    Memory Throughput                   %         9.43
    DRAM Throughput                     %         4.68
    Duration                      usecond         9.31
    L1/TEX Cache Throughput             %        31.79
    L2 Cache Throughput                 %        13.25
    SM Active Cycles                cycle     2,001.02
    Compute (SM) Throughput             %         4.36
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     32
    Registers Per Thread             register/thread             122
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           49.15
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            4
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (25.0%) is limited by the number of required registers. This kernel's     
          theoretical occupancy (25.0%) is limited by the required amount of shared memory. The difference between      
          calculated theoretical (25.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling    
          overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within  
          a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide                        
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,613
    Memory Throughput                   %        14.01
    DRAM Throughput                     %         5.87
    Duration                      usecond         9.41
    L1/TEX Cache Throughput             %        30.89
    L2 Cache Throughput                 %        14.19
    SM Active Cycles                cycle     3,838.12
    Compute (SM) Throughput             %         7.73
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,376
    Memory Throughput                   %        13.97
    DRAM Throughput                     %         4.70
    Duration                      usecond         9.22
    L1/TEX Cache Throughput             %        31.15
    L2 Cache Throughput                 %        13.97
    SM Active Cycles                cycle     3,825.43
    Compute (SM) Throughput             %         7.89
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,503
    Memory Throughput                   %        14.02
    DRAM Throughput                     %         4.66
    Duration                      usecond         9.31
    L1/TEX Cache Throughput             %        30.50
    L2 Cache Throughput                 %        14.02
    SM Active Cycles                cycle     3,875.23
    Compute (SM) Throughput             %         7.80
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       12,024
    Memory Throughput                   %        14.00
    DRAM Throughput                     %         8.77
    Duration                      usecond         9.73
    L1/TEX Cache Throughput             %        28.70
    L2 Cache Throughput                 %        14.00
    SM Active Cycles                cycle     4,109.70
    Compute (SM) Throughput             %         7.47
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,779
    Memory Throughput                   %        13.67
    DRAM Throughput                     %         7.24
    Duration                      usecond         9.50
    L1/TEX Cache Throughput             %        29.93
    L2 Cache Throughput                 %        13.67
    SM Active Cycles                cycle     3,940.85
    Compute (SM) Throughput             %         7.62
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,672
    Memory Throughput                   %        13.86
    DRAM Throughput                     %         8.97
    Duration                      usecond         9.47
    L1/TEX Cache Throughput             %        30.39
    L2 Cache Throughput                 %        13.86
    SM Active Cycles                cycle     3,851.77
    Compute (SM) Throughput             %         7.68
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,710
    Memory Throughput                   %        13.91
    DRAM Throughput                     %         5.28
    Duration                      usecond         9.50
    L1/TEX Cache Throughput             %        30.25
    L2 Cache Throughput                 %        13.91
    SM Active Cycles                cycle        3,919
    Compute (SM) Throughput             %         7.65
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       11,743
    Memory Throughput                   %        13.50
    DRAM Throughput                     %         4.57
    Duration                      usecond         9.50
    L1/TEX Cache Throughput             %        30.73
    L2 Cache Throughput                 %        13.50
    SM Active Cycles                cycle     3,857.16
    Compute (SM) Throughput             %         7.64
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              64
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           40.96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           20
    Theoretical Occupancy                     %        31.25
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (31.2%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (31.2%) and measured achieved occupancy (6.2%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,549
    Memory Throughput                   %        16.88
    DRAM Throughput                     %         5.09
    Duration                      usecond         8.58
    L1/TEX Cache Throughput             %        25.44
    L2 Cache Throughput                 %        16.88
    SM Active Cycles                cycle     6,576.81
    Compute (SM) Throughput             %         9.26
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,311
    Memory Throughput                   %        17.75
    DRAM Throughput                     %         5.19
    Duration                      usecond         8.42
    L1/TEX Cache Throughput             %        25.67
    L2 Cache Throughput                 %        17.75
    SM Active Cycles                cycle     6,550.12
    Compute (SM) Throughput             %         9.48
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.57
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,422
    Memory Throughput                   %        17.06
    DRAM Throughput                     %         5.17
    Duration                      usecond         8.48
    L1/TEX Cache Throughput             %        25.69
    L2 Cache Throughput                 %        17.06
    SM Active Cycles                cycle     6,574.02
    Compute (SM) Throughput             %         9.38
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,303
    Memory Throughput                   %        17.69
    DRAM Throughput                     %         5.22
    Duration                      usecond         8.38
    L1/TEX Cache Throughput             %        25.76
    L2 Cache Throughput                 %        17.69
    SM Active Cycles                cycle     6,530.40
    Compute (SM) Throughput             %         9.48
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,204
    Memory Throughput                   %        17.79
    DRAM Throughput                     %         5.24
    Duration                      usecond         8.29
    L1/TEX Cache Throughput             %        25.81
    L2 Cache Throughput                 %        17.79
    SM Active Cycles                cycle     6,536.72
    Compute (SM) Throughput             %         9.58
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       10,397
    Memory Throughput                   %        17.99
    DRAM Throughput                     %         5.17
    Duration                      usecond         8.45
    L1/TEX Cache Throughput             %        25.66
    L2 Cache Throughput                 %        17.99
    SM Active Cycles                cycle     6,559.85
    Compute (SM) Throughput             %         9.39
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,234
    Memory Throughput                   %        17.43
    DRAM Throughput                     %         5.23
    Duration                      usecond         8.32
    L1/TEX Cache Throughput             %        25.36
    L2 Cache Throughput                 %        17.43
    SM Active Cycles                cycle     6,626.31
    Compute (SM) Throughput             %         9.55
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,167
    Memory Throughput                   %        17.34
    DRAM Throughput                     %         5.24
    Duration                      usecond         8.29
    L1/TEX Cache Throughput             %        24.99
    L2 Cache Throughput                 %        17.34
    SM Active Cycles                cycle     6,668.23
    Compute (SM) Throughput             %         9.61
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              96
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,647
    Memory Throughput                   %        15.19
    DRAM Throughput                     %         5.03
    Duration                      usecond         8.67
    L1/TEX Cache Throughput             %        23.48
    L2 Cache Throughput                 %        13.88
    SM Active Cycles                cycle     6,862.13
    Compute (SM) Throughput             %        10.12
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,553
    Memory Throughput                   %        15.38
    DRAM Throughput                     %         5.09
    Duration                      usecond         8.58
    L1/TEX Cache Throughput             %        23.85
    L2 Cache Throughput                 %        13.94
    SM Active Cycles                cycle     6,760.13
    Compute (SM) Throughput             %        10.23
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,663
    Memory Throughput                   %        15.18
    DRAM Throughput                     %         5.02
    Duration                      usecond         8.67
    L1/TEX Cache Throughput             %        23.80
    L2 Cache Throughput                 %        13.80
    SM Active Cycles                cycle     6,766.36
    Compute (SM) Throughput             %        10.11
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,543
    Memory Throughput                   %        15.37
    DRAM Throughput                     %         5.09
    Duration                      usecond         8.58
    L1/TEX Cache Throughput             %        23.91
    L2 Cache Throughput                 %        13.87
    SM Active Cycles                cycle     6,744.78
    Compute (SM) Throughput             %        10.23
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,640
    Memory Throughput                   %        15.23
    DRAM Throughput                     %         5.05
    Duration                      usecond         8.67
    L1/TEX Cache Throughput             %        23.29
    L2 Cache Throughput                 %        13.96
    SM Active Cycles                cycle     6,923.08
    Compute (SM) Throughput             %        10.13
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,580
    Memory Throughput                   %        15.32
    DRAM Throughput                     %         5.06
    Duration                      usecond         8.61
    L1/TEX Cache Throughput             %        23.41
    L2 Cache Throughput                 %        14.08
    SM Active Cycles                cycle     6,892.75
    Compute (SM) Throughput             %        10.19
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,553
    Memory Throughput                   %        15.39
    DRAM Throughput                     %         5.09
    Duration                      usecond         8.61
    L1/TEX Cache Throughput             %        23.96
    L2 Cache Throughput                 %        13.96
    SM Active Cycles                cycle     6,747.13
    Compute (SM) Throughput             %        10.22
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (128, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.22
    Elapsed Cycles                  cycle       10,507
    Memory Throughput                   %        15.42
    DRAM Throughput                     %         5.09
    Duration                      usecond         8.54
    L1/TEX Cache Throughput             %        23.96
    L2 Cache Throughput                 %        14.28
    SM Active Cycles                cycle     6,734.28
    Compute (SM) Throughput             %        10.25
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    128
    Registers Per Thread             register/thread              93
    Shared Memory Configuration Size           Kbyte          233.47
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block           24.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    WRN   The grid for this launch is configured to execute only 128 blocks, which is less than the GPU's 132           
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           18
    Theoretical Occupancy                     %        28.12
    Achieved Occupancy                        %         3.12
    Achieved Active Warps Per SM           warp         2.00
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (28.1%) is limited by the required amount of shared memory. The           
          difference between calculated theoretical (28.1%) and measured achieved occupancy (3.1%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,745
    Memory Throughput                   %         8.70
    DRAM Throughput                     %         5.03
    Duration                      usecond         8.67
    L1/TEX Cache Throughput             %        44.90
    L2 Cache Throughput                 %        12.55
    SM Active Cycles                cycle     1,760.86
    Compute (SM) Throughput             %         4.63
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,017
    Memory Throughput                   %         8.54
    DRAM Throughput                     %         4.92
    Duration                      usecond         8.86
    L1/TEX Cache Throughput             %        44.63
    L2 Cache Throughput                 %        12.30
    SM Active Cycles                cycle     1,783.99
    Compute (SM) Throughput             %         4.52
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,121
    Memory Throughput                   %         8.43
    DRAM Throughput                     %         4.88
    Duration                      usecond         8.93
    L1/TEX Cache Throughput             %        45.29
    L2 Cache Throughput                 %        12.18
    SM Active Cycles                cycle     1,749.73
    Compute (SM) Throughput             %         4.48
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,879
    Memory Throughput                   %         8.59
    DRAM Throughput                     %         5.00
    Duration                      usecond         8.77
    L1/TEX Cache Throughput             %        44.87
    L2 Cache Throughput                 %        12.60
    SM Active Cycles                cycle     1,775.83
    Compute (SM) Throughput             %         4.58
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,787
    Memory Throughput                   %         8.64
    DRAM Throughput                     %         5.03
    Duration                      usecond         8.67
    L1/TEX Cache Throughput             %        44.19
    L2 Cache Throughput                 %        12.70
    SM Active Cycles                cycle     1,798.10
    Compute (SM) Throughput             %         4.62
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,959
    Memory Throughput                   %         8.64
    DRAM Throughput                     %         4.96
    Duration                      usecond         8.83
    L1/TEX Cache Throughput             %        43.76
    L2 Cache Throughput                 %        12.35
    SM Active Cycles                cycle     1,807.95
    Compute (SM) Throughput             %         4.55
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,075
    Memory Throughput                   %         8.61
    DRAM Throughput                     %         4.91
    Duration                      usecond         8.90
    L1/TEX Cache Throughput             %        43.73
    L2 Cache Throughput                 %        12.92
    SM Active Cycles                cycle     1,820.34
    Compute (SM) Throughput             %         4.50
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       11,205
    Memory Throughput                   %        48.65
    DRAM Throughput                     %         5.12
    Duration                      usecond         8.99
    L1/TEX Cache Throughput             %        42.32
    L2 Cache Throughput                 %            0
    SM Active Cycles                cycle     1,878.15
    Compute (SM) Throughput             %         4.45
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,633
    Memory Throughput                   %         8.39
    DRAM Throughput                     %         5.11
    Duration                      usecond         8.54
    L1/TEX Cache Throughput             %        38.92
    L2 Cache Throughput                 %        13.70
    SM Active Cycles                cycle     1,732.40
    Compute (SM) Throughput             %         4.68
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,496
    Memory Throughput                   %         8.51
    DRAM Throughput                     %         5.16
    Duration                      usecond         8.45
    L1/TEX Cache Throughput             %        40.22
    L2 Cache Throughput                 %        13.80
    SM Active Cycles                cycle     1,686.14
    Compute (SM) Throughput             %         4.75
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,436
    Memory Throughput                   %         8.55
    DRAM Throughput                     %         5.20
    Duration                      usecond         8.42
    L1/TEX Cache Throughput             %        40.28
    L2 Cache Throughput                 %        14.06
    SM Active Cycles                cycle     1,673.02
    Compute (SM) Throughput             %         4.77
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,429
    Memory Throughput                   %         8.55
    DRAM Throughput                     %         5.21
    Duration                      usecond         8.38
    L1/TEX Cache Throughput             %        40.51
    L2 Cache Throughput                 %        14.03
    SM Active Cycles                cycle     1,661.60
    Compute (SM) Throughput             %         4.78
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,403
    Memory Throughput                   %         8.59
    DRAM Throughput                     %         5.21
    Duration                      usecond         8.38
    L1/TEX Cache Throughput             %        40.37
    L2 Cache Throughput                 %        14.09
    SM Active Cycles                cycle     1,668.17
    Compute (SM) Throughput             %         4.79
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,524
    Memory Throughput                   %         8.48
    DRAM Throughput                     %         5.16
    Duration                      usecond         8.48
    L1/TEX Cache Throughput             %        39.51
    L2 Cache Throughput                 %        13.88
    SM Active Cycles                cycle     1,701.92
    Compute (SM) Throughput             %         4.73
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       10,605
    Memory Throughput                   %         8.40
    DRAM Throughput                     %         5.11
    Duration                      usecond         8.54
    L1/TEX Cache Throughput             %        40.32
    L2 Cache Throughput                 %        14.45
    SM Active Cycles                cycle     1,675.31
    Compute (SM) Throughput             %         4.69
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (32, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle       10,384
    Memory Throughput                   %         8.58
    DRAM Throughput                     %         5.24
    Duration                      usecond         8.38
    L1/TEX Cache Throughput             %        38.79
    L2 Cache Throughput                 %        13.95
    SM Active Cycles                cycle     1,740.67
    Compute (SM) Throughput             %         4.80
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       32
    Registers Per Thread             register/thread               128
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             98.30
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             4,096
    Waves Per SM                                                  0.12
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,568
    Memory Throughput                   %        13.28
    DRAM Throughput                     %         5.63
    Duration                      usecond         7.71
    L1/TEX Cache Throughput             %        44.66
    L2 Cache Throughput                 %        14.42
    SM Active Cycles                cycle     2,827.09
    Compute (SM) Throughput             %         8.11
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,298
    Memory Throughput                   %        13.74
    DRAM Throughput                     %         5.79
    Duration                      usecond         7.52
    L1/TEX Cache Throughput             %        44.66
    L2 Cache Throughput                 %        14.83
    SM Active Cycles                cycle     2,848.45
    Compute (SM) Throughput             %         8.33
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,391
    Memory Throughput                   %        13.81
    DRAM Throughput                     %         5.74
    Duration                      usecond         7.62
    L1/TEX Cache Throughput             %        45.63
    L2 Cache Throughput                 %        14.75
    SM Active Cycles                cycle     2,830.27
    Compute (SM) Throughput             %         8.25
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,368
    Memory Throughput                   %        13.56
    DRAM Throughput                     %         5.74
    Duration                      usecond         7.58
    L1/TEX Cache Throughput             %        44.73
    L2 Cache Throughput                 %        14.79
    SM Active Cycles                cycle     2,829.03
    Compute (SM) Throughput             %         8.27
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.58
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,635
    Memory Throughput                   %        13.12
    DRAM Throughput                     %         5.62
    Duration                      usecond         7.78
    L1/TEX Cache Throughput             %        43.37
    L2 Cache Throughput                 %        14.54
    SM Active Cycles                cycle     2,897.97
    Compute (SM) Throughput             %         8.06
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,344
    Memory Throughput                   %        13.43
    DRAM Throughput                     %         5.82
    Duration                      usecond         7.58
    L1/TEX Cache Throughput             %        43.15
    L2 Cache Throughput                 %        12.92
    SM Active Cycles                cycle     2,894.21
    Compute (SM) Throughput             %         8.30
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,298
    Memory Throughput                   %        13.49
    DRAM Throughput                     %         5.76
    Duration                      usecond         7.55
    L1/TEX Cache Throughput             %        44.10
    L2 Cache Throughput                 %        14.87
    SM Active Cycles                cycle     2,836.10
    Compute (SM) Throughput             %         8.32
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.23
    Elapsed Cycles                  cycle        9,469
    Memory Throughput                   %        13.40
    DRAM Throughput                     %         5.70
    Duration                      usecond         7.65
    L1/TEX Cache Throughput             %        42.37
    L2 Cache Throughput                 %        14.76
    SM Active Cycles                cycle     2,982.13
    Compute (SM) Throughput             %         8.18
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       64
    Registers Per Thread             register/thread                96
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             81.92
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             8,192
    Waves Per SM                                                  0.24
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.22
    Achieved Active Warps Per SM           warp         3.98
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the required amount of shared memory. See the CUDA  
          Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for      
          more details on optimizing occupancy.                                                                         

  matmul_kernel (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.59
    SM Frequency            cycle/nsecond         1.24
    Elapsed Cycles                  cycle       14,180
    Memory Throughput                   %         6.87
    DRAM Throughput                     %         3.84
    Duration                      usecond        11.39
    L1/TEX Cache Throughput             %        42.95
    L2 Cache Throughput                 %        10.11
    SM Active Cycles                cycle     1,287.73
    Compute (SM) Throughput             %         3.51
    ----------------------- ------------- ------------

    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- -----------------
    Metric Name                          Metric Unit      Metric Value
    -------------------------------- --------------- -----------------
    Block Size                                                     128
    Cluster Scheduling Policy                             PolicySpread
    Cluster Size                                                     0
    Function Cache Configuration                     CachePreferShared
    Grid Size                                                       16
    Registers Per Thread             register/thread               190
    Shared Memory Configuration Size           Kbyte            233.47
    Driver Shared Memory Per Block       Kbyte/block              1.02
    Dynamic Shared Memory Per Block      Kbyte/block             65.54
    Static Shared Memory Per Block        byte/block                 0
    Threads                                   thread             2,048
    Waves Per SM                                                  0.06
    -------------------------------- --------------- -----------------

    WRN   The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp            8
    Theoretical Occupancy                     %        12.50
    Achieved Occupancy                        %         6.23
    Achieved Active Warps Per SM           warp         3.99
    ------------------------------- ----------- ------------

    WRN   This kernel's theoretical occupancy (12.5%) is limited by the number of required registers. See the CUDA Best 
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

