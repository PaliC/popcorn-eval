==PROF== Connected to process 2628030 (/home/sahanp/.conda/envs/parity-bench/bin/python3.11)
==PROF== Disconnected from process 2628030
"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","DRAM Frequency","hz","1,590,406,719.72",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","SM Frequency","hz","1,322,384,781.17",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","16,094",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Memory Throughput","%","39.34",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","DRAM Throughput","%","19.35",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Duration","ns","12,064",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","58.58",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","33.39",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","10,714.05",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","38.90",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","SpeedOfLight","","","","SOLBottleneck","OPT","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.","",""
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Block Size","","256",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Cluster Scheduling Policy","","PolicySpread",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Cluster Size","","0",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Grid Size","","1,056",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Registers Per Thread","register/thread","32",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Shared Memory Configuration Size","byte","135,168",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","12,320",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","# SMs","SM","132",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Threads","thread","270,336",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Uses Green Context","","0",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Launch Statistics","Waves Per SM","","1",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Max Active Clusters","cluster","0",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Max Cluster Size","block","8",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Overall GPU Occupancy","%","0",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Cluster Occupancy","%","0",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Block Limit Barriers","block","32",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Block Limit SM","block","32",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Block Limit Registers","block","8",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Block Limit Shared Mem","block","10",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Block Limit Warps","block","8",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Theoretical Active Warps per SM","warp","64",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Theoretical Occupancy","%","100",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Achieved Occupancy","%","86.48",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","Achieved Active Warps Per SM","warp","55.35",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","local","13.52"
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","3,712.33",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","920,960",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","10,714.05",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,105,578",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","11,588.46",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,553,568",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","10,714.05",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,105,578",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","10,587.58",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","8,422,312",
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 11.80% above the average, while the minimum instance value is 8.87% below the average.","global","7.924"
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 13.63% above the average, while the minimum instance value is 7.15% below the average.","global","9.045"
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 11.80% above the average, while the minimum instance value is 8.87% below the average.","global","7.924"
"0","2628030","python3.11","127.0.0.1","softmax_kernel","1","7","(256, 1, 1)","(1056, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L2 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 8.52% above the average, while the minimum instance value is 4.42% below the average.","global","6.102"
