==PROF== Connected to process 2593601 (/home/sahanp/.conda/envs/parity-bench/bin/python3.11)
==PROF== Disconnected from process 2593601
"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","DRAM Frequency","hz","1,590,922,358.44",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","SM Frequency","hz","1,341,636,109.89",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","24,586",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Memory Throughput","%","39.08",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","DRAM Throughput","%","18.84",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Duration","ns","18,272",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","19.24",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","64.63",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","19,826.25",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.91",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","SpeedOfLight","","","","SOLBottleneck","OPT","This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full waves across all SMs. Look at Launch Statistics for more details.","",""
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Block Size","","128",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Cluster Scheduling Policy","","PolicySpread",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Cluster Size","","0",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Grid Size","","1,024",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Registers Per Thread","register/thread","40",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Shared Memory Configuration Size","byte","32,768",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","16",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","# SMs","SM","132",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Threads","thread","131,072",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Uses Green Context","","0",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Launch Statistics","Waves Per SM","","0.65",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Max Active Clusters","cluster","0",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Max Cluster Size","block","8",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Overall GPU Occupancy","%","0",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Cluster Occupancy","%","0",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Block Limit Barriers","block","32",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Block Limit SM","block","32",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Block Limit Registers","block","12",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Block Limit Shared Mem","block","28",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Block Limit Warps","block","16",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Theoretical Active Warps per SM","warp","48",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Theoretical Occupancy","%","75",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Achieved Occupancy","%","34.66",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","Achieved Active Warps Per SM","warp","22.18",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (75.0%) and measured achieved occupancy (34.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","local","53.79"
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","Occupancy","","","","TheoreticalOccupancy","OPT","The 12.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 16. This kernel's theoretical occupancy (75.0%) is limited by the number of required registers.","local","25"
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,475.83",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,395,328",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","19,826.25",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","3,235,780",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","21,056.65",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","2,348,928",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","19,826.25",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","3,235,780",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","18,906.55",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","12,943,120",
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 12.16% above the average, while the minimum instance value is 20.83% below the average.","global","9.838"
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 14.00% above the average, while the minimum instance value is 24.61% below the average.","global","10.8"
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 12.16% above the average, while the minimum instance value is 20.83% below the average.","global","9.838"
"0","2593601","python3.11","127.0.0.1","_layer_norm_bwd_dx_fused","1","7","(128, 1, 1)","(1024, 1, 1)","0","9.0","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L2 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.90% above the average, while the minimum instance value is 1.69% below the average.","global","5.078"
